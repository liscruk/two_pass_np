import os
import sys
import re

configfile: "config.yml"

RESULTS=os.path.join(config["resultsdir"],str(config["experiment"]+"/"))
SAMPLES = expand(config["samples"])
SOURCE = config["source"]
ASSAY = config["experiment"]

sys.stderr.write("Version 1.0")

def getOutput(Folder):
	
	fList = []

	for x in os.listdir(Folder):
		if re.match(r".+abundance.+"):
			fList.append(os.path.join(Folder,x))

	return fList

OUTS_TPM = expand(RESULTS+"analysis/tpm/{sample}.abundance.tsv",sample=SAMPLES)

# Generate all output files.
rule all:
	input:
		# TPM generated from Stringtie for all annotated genes
		RESULTS+"analysis/merge/All.TPM.tsv",
		# Integer count of gene levels generated by feature counts
		RESULTS+"analysis/merge/All.Counts.tsv",
		# Transcript tpms generated by stringtie
		RESULTS+"analysis/merge/All.Transcripts.salmon.tsv",

		expand(RESULTS+"data/bam_unmapped/{sample}.unmpapped.genomic.bam",sample = SAMPLES),
		expand(RESULTS+"data/bam_unmapped/{sample}.unmpapped.transcriptomic.bam",sample = SAMPLES),


# Spliced mapping against the entire genome
rule minimap2splice:
	input:
		reads = lambda wildcards: config["samples"][wildcards.sample],
		index = config["index"]
	output:
		RESULTS+"data/bam/{sample}.bam"
	threads: config["threads"]
	shell:
		"minimap2 -t {threads} -ax splice -k '14' -u 'f'  {input.index} {input.reads} | samtools sort -@ 20 | samtools view -hbS -@ 20 > {output}"

# Non-splice full length mapping against the generated transcriptome
rule minimap2full:
	input:
		reads = lambda wildcards: config["samples"][wildcards.sample],
		index = RESULTS+"data/transcriptome/"+ASSAY+".index.mmi",
		transcripts = RESULTS+"data/transcriptome/"+ASSAY+".ref.trps.fa"
	output:
		sbam = RESULTS+"data/bam/{sample}.transcripts.sorted.bam"
	threads: config["threads"]
	shell:"""
	minimap2 -t {threads} -ax map-ont -p 1.0 -N 100 {input.index} {input.reads} | samtools sort -@ 20 |  samtools view -Sb > {output.sbam};
    samtools index {output.sbam};
    """

rule builtIndex:
	input:
		transcriptome=RESULTS+"data/transcriptome/"+ASSAY+".ref.trps.fa",
	output:
		index=RESULTS+"data/transcriptome/"+ASSAY+".index.mmi",
	threads:config["threads"]
	shell:
		"minimap2 -t {threads} -d {output.index} {input.transcriptome}"


# Generate transcriptome assembly from stringtie merged transcripts
rule makeTranscripts:
	input:
		trps = expand(RESULTS+"analysis/tpm/{sample}.transcripts.gtf",sample=SAMPLES),
		annotation = config["ref_annotation"],
	output:
		trp_ref = RESULTS+"data/transcriptome/"+ASSAY+".ref.trps.gtf",
	shell:"""
		stringtie --merge {input.trps} -G {input.annotation} > {output.trp_ref}
	"""

rule makeTranscriptome:
	input:
		gtf = RESULTS+"data/transcriptome/"+ASSAY+".annotated.gtf",
		reference = config["ref_genome"]
	output:
		trp_fa = RESULTS+"data/transcriptome/"+ASSAY+".ref.trps.fa"
	shell:
		"gffread -w {output.trp_fa} -g {input.reference} {input.gtf} -F"

rule benchmarkTranscriptome:
	input:
		strg_gtf = RESULTS+"data/transcriptome/"+ASSAY+".ref.trps.gtf",
		genome = config['ref_genome'],
		ref_gtf = config['ref_annotation']
	output:
		RESULTS+"data/transcriptome/"+ASSAY+".stats",
		RESULTS+"data/transcriptome/"+ASSAY+".annotated.gtf"
	shell:
		"gffcompare -R -r {input.ref_gtf} -s {input.genome} -o {RESULTS}/data/transcriptome/{ASSAY} {input.strg_gtf}"

rule salmonQuant:
	input:
		bam = RESULTS+"data/bam/{sample}.transcripts.sorted.bam",
		trp = RESULTS+"data/transcriptome/"+ASSAY+".ref.trps.fa"
	output:
		trp_quant = RESULTS+"analysis/counts/{sample}/quant.sf"
	threads: config["threads"]
	params:
		outDir = RESULTS+"analysis/counts/{sample}/"
	shell:
		"salmon quant --noErrorModel -p {threads} -l U -t {input.trp} -a {input.bam} -o {params.outDir}"

rule extractUnmapped:
	input:
		gbam = RESULTS+"data/bam/{sample}.transcripts.sorted.bam",
		tbam = RESULTS+"data/bam/{sample}.bam"
	output:
		gUbam = RESULTS+"data/bam_unmapped/{sample}.unmpapped.genomic.bam",
		tUbam = RESULTS+"data/bam_unmapped/{sample}.unmpapped.transcriptomic.bam"
		
	shell:"""
		samtools view -b -f 4 {input.gbam} > {output.gUbam};
		samtools view -b -f 4 {input.tbam} > {output.tUbam}
	"""

# Mapping statistics for primary alignment
rule mapStats:
	input:
		bam = RESULTS+"data/bam/{sample}.bam",
		tbam = RESULTS+"data/bam/{sample}.transcripts.sorted.bam",
		model = config["ref_model"]

	output:
		readDist = temp(RESULTS+"data/stats/{sample}.read-stats.raw.txt"),
		readDistTranscripts = RESULTS+"data/stats/{sample}.transcriptome.read-stats.raw.txt"

	shell:"""
		
		read_distribution.py -i {input.bam} -r {input.model} > {output.readDist};
		samtools flagstat {input.tbam} > {output.samTranscriptomicOut};
	"""
		
# Generate integer counts fo gene level differential expression analysis
rule makeCounts:
	input:
		ano = config["ref_annotation"],
		bam = RESULTS+"data/bam/{sample}.bam"

	output:
		RESULTS+"analysis/counts/{sample}.counts.tsv"

	threads: config["threads"]
	shell:
		"featureCounts -t gene -T {threads} -L -a {input[0]} -t exon -g gene_id -o {output} {input[1]}"

# Transcripts per million on gene level
rule makeTPM:
	input:
		annotation=config["ref_annotation"],
		alignment=RESULTS+"data/bam/{sample}.bam"
	output:
		abundance=RESULTS+"analysis/tpm/{sample}.abundance.tsv",
		gtf=RESULTS+"analysis/tpm/{sample}.transcripts.gtf"

	threads: config["threads"]
	
	shell:
		"stringtie {input.alignment} --conservative -G {input.annotation} -L -A {output.abundance} > {output.gtf}"

# Simple aggregation for output file
### AGGREGATION BLOCK ####

rule aggregateTPM:
	input:
		abundance = expand(RESULTS+"analysis/tpm/{sample}.abundance.tsv",sample=SAMPLES)
	output:
		tpmFile = RESULTS+"analysis/merge/All.TPM.tsv"
	shell:
		"{SOURCE}/PostProcess.py {input.abundance} -t tpm > {output.tpmFile}"

rule aggregateCount:
	input:
		counts = expand(RESULTS+"analysis/counts/{sample}.counts.tsv",sample=SAMPLES)
	output:
		countFile = RESULTS+"analysis/merge/All.Counts.tsv"
	shell:
		"{SOURCE}/PostProcess.py {input.counts} -t counts > {output.countFile}"


rule aggregateTranscripts:
	input:
		trps = expand(RESULTS+"analysis/tpm/{sample}.annotated.transcripts.tsv",sample=SAMPLES)
	output:
		trpFile = RESULTS+"analysis/merge/All.Annotated.Transcripts.tsv"
	shell:
		"{SOURCE}/PostProcess.py {input.trps} -t transcripts > {output.trpFile}"

rule aggregateSalmon:
	input:
		trps = expand(RESULTS+"analysis/counts/{sample}/quant.sf",sample=SAMPLES)
	output:
		trpFile = RESULTS+"analysis/merge/All.Transcripts.salmon.tsv"
	shell:
		"{SOURCE}/PostProcess.py {input.trps} -t salmon > {output.trpFile}"


### AGGREGATION BLOCK END####

# Formatting and reorganizing
### FORMATING BLOCK ### 
rule processTranscripts:
	input:
		gtf=RESULTS+"analysis/tpm/{sample}.transcripts.gtf"
	output:
		temp(RESULTS+"analysis/tpm/{sample}.tmp.transcripts.tsv")
	shell:
		"{SOURCE}/gtfprocess.sh {input.gtf} {output}"

rule extractAnnotated:
	input:
		allTrp = RESULTS+"analysis/tpm/{sample}.tmp.transcripts.tsv"
	output:
		annotated = RESULTS+"analysis/tpm/{sample}.annotated.transcripts.tsv"
	shell:
		"{SOURCE}/annotation.sh {input.allTrp} {output.annotated}"

rule formatStat:
	input:
		stats = RESULTS+"data/stats/{sample}.read-stats.raw.txt"
	output:
		formatStats = RESULTS+"data/stats/{sample}.read-stats.txt"
	shell:
		"{SOURCE}/stats.sh {input.stats} {output.formatStats}"

rule aggregateStats:
	input:
		allStat = expand(RESULTS+"data/stats/{sample}.read-stats.txt",sample=SAMPLES)
	output:
		statFile = RESULTS+"analysis/merge/All.Stats.tsv"
	shell:
		"{SOURCE}/PostProcess.py {input.allStat} -t stats > {output.statFile}"

### FORMATTING BLOCK END ###
